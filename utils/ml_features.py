"""ML feature engineering and labeling for market data.

Designed to work with OHLCV + indicator CSVs generated by `projects/market_analyzer.py`.

Key goals:
- Avoid lookahead bias: features use only current/past candles.
- Provide simple, reproducible labels for supervised ML.

This is for research/education only; not financial advice.
"""

from __future__ import annotations

from dataclasses import dataclass

import numpy as np
import pandas as pd


def _ema(series: pd.Series, span: int) -> pd.Series:
    return series.astype(float).ewm(span=span, adjust=False, min_periods=span).mean()


def macd(close: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> tuple[pd.Series, pd.Series, pd.Series]:
    """MACD line, signal line, histogram."""
    c = close.astype(float)
    macd_line = _ema(c, fast) - _ema(c, slow)
    signal_line = _ema(macd_line, signal)
    hist = macd_line - signal_line
    return macd_line, signal_line, hist


def bollinger_bands(close: pd.Series, period: int = 20, n_std: float = 2.0) -> tuple[pd.Series, pd.Series, pd.Series]:
    c = close.astype(float)
    mid = c.rolling(period, min_periods=period).mean()
    std = c.rolling(period, min_periods=period).std(ddof=0)
    upper = mid + n_std * std
    lower = mid - n_std * std
    return lower, mid, upper


@dataclass(frozen=True)
class LabelSpec:
    horizon: int = 5
    task: str = "classification"  # classification | regression
    threshold: float = 0.002  # 0.2% by default


def future_return(close: pd.Series, horizon: int) -> pd.Series:
    c = close.astype(float)
    return c.shift(-horizon) / c - 1.0


def make_labels(close: pd.Series, spec: LabelSpec) -> pd.Series:
    """Create labels from future returns.

    - classification: {-1, 0, +1} => sell/hold/buy
    - regression: future return (float)

    Labels on the last `horizon` rows will be NaN (no future data).
    """
    fr = future_return(close, spec.horizon)

    task = (spec.task or "classification").strip().lower()
    if task in {"regression", "reg", "return"}:
        return fr

    thr = float(spec.threshold)
    y = pd.Series(index=fr.index, dtype="float")
    y[fr > thr] = 1.0
    y[fr < -thr] = -1.0
    y[(fr <= thr) & (fr >= -thr)] = 0.0
    return y


def build_features(df: pd.DataFrame) -> pd.DataFrame:
    """Build a feature matrix from an OHLCV(+indicator) DataFrame.

    Expected columns: Open, High, Low, Close, Volume
    Optional columns (from market analyzer): RSI14, Tenkan, Kijun, SenkouA, SenkouB

    Returns a new DataFrame with numeric feature columns.
    """
    out = pd.DataFrame(index=df.index)

    # Core price/volume
    o = df["Open"].astype(float)
    h = df["High"].astype(float)
    l = df["Low"].astype(float)
    c = df["Close"].astype(float)

    out["close"] = c
    out["log_return_1"] = np.log(c).diff(1)
    out["return_1"] = c.pct_change(1)
    out["return_5"] = c.pct_change(5)

    # Candle structure
    out["range"] = (h - l)
    out["body"] = (c - o)
    out["body_abs"] = (c - o).abs()
    out["upper_wick"] = (h - np.maximum(o, c))
    out["lower_wick"] = (np.minimum(o, c) - l)
    out["body_to_range"] = out["body_abs"] / out["range"].replace(0.0, np.nan)

    # Rolling volatility proxies
    out["volatility_10"] = out["return_1"].rolling(10, min_periods=10).std(ddof=0)
    out["volatility_20"] = out["return_1"].rolling(20, min_periods=20).std(ddof=0)

    # SMAs (trend)
    for p in (10, 20, 50, 100, 200):
        out[f"sma_{p}"] = c.rolling(p, min_periods=p).mean()
        out[f"close_over_sma_{p}"] = c / out[f"sma_{p}"] - 1.0

    # EMAs
    for p in (12, 26):
        out[f"ema_{p}"] = _ema(c, p)
        out[f"close_over_ema_{p}"] = c / out[f"ema_{p}"] - 1.0

    # MACD
    macd_line, macd_signal, macd_hist = macd(c)
    out["macd"] = macd_line
    out["macd_signal"] = macd_signal
    out["macd_hist"] = macd_hist

    # Bollinger
    bb_l, bb_m, bb_u = bollinger_bands(c)
    out["bb_lower"] = bb_l
    out["bb_mid"] = bb_m
    out["bb_upper"] = bb_u
    out["bb_width"] = (bb_u - bb_l) / bb_m.replace(0.0, np.nan)
    out["bb_pos"] = (c - bb_l) / (bb_u - bb_l).replace(0.0, np.nan)

    # Volume (if present)
    if "Volume" in df.columns:
        v = pd.to_numeric(df["Volume"], errors="coerce")
        out["volume"] = v
        out["volume_sma_20"] = v.rolling(20, min_periods=20).mean()
        out["volume_over_sma_20"] = v / out["volume_sma_20"].replace(0.0, np.nan) - 1.0

    # Bring in existing indicators if present
    for col in ("RSI14", "Tenkan", "Kijun", "SenkouA", "SenkouB"):
        if col in df.columns:
            out[col.lower()] = pd.to_numeric(df[col], errors="coerce")

    # Exogenous numeric columns (macro series, fundamentals, etc.)
    # If the caller merges additional data sources into the raw frame, include
    # them automatically as features.
    exclude = {
        "open",
        "high",
        "low",
        "close",
        "adj close",
        "volume",
        "dividends",
        "stock splits",
        "rsi14",
        "tenkan",
        "kijun",
        "senkoua",
        "senkoub",
    }
    for c_name in df.columns:
        key = str(c_name).strip().lower()
        if key in exclude:
            continue
        # Keep only numeric-ish columns.
        ser = pd.to_numeric(df[c_name], errors="coerce")
        if ser.notna().any():
            out[f"ext_{key}"] = ser

    return out


def make_sequences(X: pd.DataFrame, y: pd.Series, lookback: int) -> tuple[np.ndarray, np.ndarray, list[pd.Timestamp]]:
    """Convert tabular features into rolling sequences for LSTM/TCN-style models.

    Returns:
      - X_seq: shape (n_samples, lookback, n_features)
      - y_seq: shape (n_samples,)
      - end_times: timestamps corresponding to the last row in each sequence

    Note: This does not do any scaling; do that in your model pipeline.
    """
    if lookback < 2:
        raise ValueError("lookback must be >= 2")

    Xv = X.to_numpy(dtype=float)
    yv = y.to_numpy()

    end_times: list[pd.Timestamp] = []
    X_seq: list[np.ndarray] = []
    y_seq: list[float] = []

    for i in range(lookback - 1, len(X)):
        if pd.isna(y.iloc[i]):
            continue
        window = Xv[i - lookback + 1 : i + 1]
        if np.isnan(window).all():
            continue
        X_seq.append(window)
        y_seq.append(float(yv[i]))
        end_times.append(X.index[i])

    return np.asarray(X_seq), np.asarray(y_seq), end_times
